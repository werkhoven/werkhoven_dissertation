@article{Chiappe_Walking_2010,
  author={Chiappe, Eugenia M and Seelig, Johannes D and Reiser, Michael B and Jayaraman, Vivek},
  year={2010},
  volume={20},
  number={16},
  issn={0960-9822},
  pages={1470-1475},
  title={Walking Modulates Speed Sensitivity in Drosophila Motion Vision},
  doi={10.1016/j.cub.2010.06.072}
}
@article{Gtz_Visual_1973,title={Visual control of locomotion in the walking fruitfly Drosophila}, volume={85}, DOI={10.1007/bf00694232}, number={3}, journal={Journal of Comparative Physiology}, author={Götz, Karl Georg and Wenking, Hans}, year={1973}, pages={235–266}}
@article{Stowers_Virtual_2017,title={Virtual reality for freely moving animals}, volume={14}, DOI={10.1038/nmeth.4399}, number={10}, journal={Nature Methods}, author={Stowers, John R and Hofbauer, Maximilian and Bastien, Renaud and Griessner, Johannes and Higgins, Peter and Farooqui, Sarfarazhussain and Fischer, Ruth M and Nowikovsky, Karin and Haubensak, Wulf and Couzin, Iain D and et al.}, year={2017}, pages={995–1002}}
@article{Kain_Variability_2015,
  author={Kain, Jamey S and Zhang, Sarah and {Akhund‐Zade,} Jamilla and Samuel, Aravinthan {DT} and Klein, Mason and Bivort, Benjamin L},
  year={2015},
  volume={69},
  number={12},
  journal={Evolution},
  pmid={26531165},
  issn={1558-5646},
  pages={3171-3185},
  title={Variability in thermal and phototactic preferences in Drosophila may reflect an adaptive bet‐hedging strategy},
  doi={10.1111/evo.12813}
}
@article{Seelig_Two_2010,title={Two-photon calcium imaging from head-fixed Drosophila during optomotor walking behavior}, volume={8}, DOI={10.1038/nmeth.1468}, number={2}, journal={Nature Methods}, author={Seelig, Johannes D and Chiappe, M Eugenia and Lott, Gus K and Dutta, Anirban and Osborne, Jason E and Reiser, Michael B and Jayaraman, Vivek}, year={2010}, pages={184–184}}

@article{Sridhar_2019,
author = {Sridhar, Vivek Hari and Roche, Dominique G. and Gingins, Simon},
title = {Tracktor: Image-based automated tracking of animal movement and behaviour},
year = {2019},
journal = {Methods in Ecology and Evolution},
volume = {0},
number = {0},
pages = {},
keywords = {choice experiment, collective behaviour, fast-start escape response, kinematics, locomotion, video analysis software},
doi = {10.1111/2041-210X.13166},
}


@article{Fry_TrackFly_2008,
  author={Fry, Steven and Rohrseitz, Nicola and Straw, Andrew and Dickinson, Michael},
  year={2008},
  volume={171},
  number={1},
  journal={J Neurosci Meth},
  pmid={18405978},
  file={C:\Users\werkh\OneDrive\Documents\ReadCube Media\TrackFly.pdf},
  abstract={Modern neuroscience and the interest in biomimetic control design demand increasingly sophisticated experimental techniques that can be applied in freely moving animals under realistic behavioral conditions. To explore sensorimotor flight control mechanisms in free-flying fruit flies {(Drosophila} melanogaster), we equipped a wind tunnel with a Virtual Reality {(VR)} display system based on standard digital hardware and a {3D} path tracking system. We demonstrate the experimental power of this approach by example of a ‘one-parameter open loop’ testing paradigm. It provided (1) a straightforward measure of transient responses in presence of open loop visual stimulation; (2) high data throughput and standardized measurement conditions from process automation; and (3) simplified data analysis due to well-defined testing {conditions.Being} based on standard hardware and software techniques, our methods provide an affordable, easy to replicate and general solution for a broad range of behavioral applications in freely moving animals. Particular relevance for advanced behavioral research tools originates from the need to perform detailed behavioral analyses in genetically modified organisms and animal models for disease research.},
  issn={0165-0270},
  pages={110-117},
  title={{TrackFly:} Virtual reality for a behavioral system analysis in free-flying fruit flies},
  doi={10.1016/j.jneumeth.2008.02.016}
}
@article{Rodriguez_ToxId_2017,title={ToxId: an efficient algorithm to solve occlusions when tracking multiple animals}, volume={7}, DOI={10.1038/s41598-017-15104-2}, number={1}, journal={Scientific Reports}, author={Rodriguez, Alvaro and Zhang, Hanqing and Klaminder, Jonatan and Brodin, Tomas and Andersson, Magnus}, year={2017}}
@article{Chagas_The_2017,
  author={Chagas, Andre and {Prieto-Godino,} Lucia L and Arrenberg, Aristides B and Baden, Tom},
  year={2017},
  volume={15},
  number={7},
  journal={Plos Biol},
  pmid={28719603},
  issn={1544-9173},
  pages={e2002702},
  title={The €100 lab: A {3D-printable} open-source platform for fluorescence microscopy, optogenetics, and accurate temperature control during behaviour of zebrafish, Drosophila, and Caenorhabditis elegans},
  doi={10.1371/journal.pbio.2002702}
}
@article{Ramot_The_2008,
  author={Ramot, D and Johnson, {BE} and Jr, Berry {TL} and one, Carnell~- L},
  year={2008},
  journal={{PloS} one},
  title={The Parallel Worm Tracker: a platform for measuring average speed and drug-induced paralysis in nematodes}
}
@article{Kuhn_The_1955,
  author={Kuhn, Harold W},
  year={1955},
  volume={2},
  number={1 2},
  pages={83-97},
  title={The Hungarian method for the assignment problem}
}
@article{Chiang_Tactic_1963,
  author={Chiang, {HC}},
  year={1963},
  volume={70},
  number={2},
  issn={0003-0031},
  pages={329},
  title={Tactic Reactions of Young Adults of Drosophila melanogaster},
  doi={10.2307/2423061}
}
@article{Todd_Systematic_2017,
  author={Todd, Jeremy G and Kain, Jamey S and de Bivort, Benjamin L},
  year={2017},
  volume={14},
  number={1},
  journal={Phys Biol},
  pmid={28166059},
  issn={1478-3975},
  pages={015002},
  title={Systematic exploration of unsupervised methods for mapping behavior},
  doi={10.1088/1478-3975/14/1/015002}
}
@article{Lochmatter_Swistrack_2008,
  author={Lochmatter, T and Roduit, P and {IEEE/RSJ~…,} Cianci~- C},
  year={2008},
  abstract={Vision-based tracking is used in nearly all robotic laboratories for monitoring and extracting of agent positions, orientations, and trajectories. However, there is currently no accepted standard software solution available, so many research groups resort to developing and using their own custom software. In this paper, we present version 4 of {SwisTrack,} an open source project for simultaneous tracking of multiple agents. While its broad range of pre-implemented algorithmic components allows it to be used in a variety of experimental~…},
  title={Swistrack-a flexible open source tracking software for multi-agent systems}
}
@article{Strauss_Processing_1997,author = {Strauss, R and Schuster, S and G{\"o}tz, K G},
	title = {Processing of artificial visual feedback in the walking fruit fly Drosophila melanogaster.},
	volume = {200},
	number = {9},
	pages = {1281--1296},
	year = {1997},
	publisher = {The Company of Biologists Ltd},
	issn = {0022-0949},
	journal = {Journal of Experimental Biology}
}

@article{Kain_Phototactic_2012,
  author={Kain, Jamey S and Stokes, Chris and de Bivort, Benjamin L},
  year={2012},
  volume={109},
  number={48},
  journal={Proc National Acad Sci},
  pmid={23150588},
  issn={0027-8424},
  pmcid={{PMC3511718}},
  pages={19834-19839},
  title={Phototactic personality in fruit flies and its suppression by serotonin and white},
  doi={10.1073/pnas.1211988109}
}
@article{Zhu_Peripheral_2009,
  author={Zhu, Y and Nern, A and Zipursky, {SL} and Biology, Frye~- {MA}},
  year={2009},
  journal={Current Biology},
  abstract={Like the mammalian visual cortex, the fly visual system is organized into retinotopic columns 1, 2. A widely accepted biophysical model for computing visual motion, the elementary motion detector proposed nearly 50 years ago [3] posits a temporal correlation of spatially separated visual inputs implemented across neighboring retinotopic visual columns. Whereas the inputs are defined [4], the neural substrate for motion computation remains enigmatic. Indeed, it is not known where in the visual processing hierarchy the computation~…},
  title={Peripheral visual circuits functionally segregate motion and phototaxis behaviors in the fly}
}
@article{Rien_Octopaminergic_2013,
  author={Rien, Diana and Kern, Roland and Kurtz, Rafael},
  year={2013},
  volume={7},
  issn={1662-5153},
  title={Octopaminergic modulation of a fly visual motion-sensitive neuron during stimulation with naturalistic optic flow},
  doi={10.3389/fnbeh.2013.00155}
}
@article{Buchanan_Neuronal_2015,
  author={Buchanan, Sean M and Kain, Jamey S and de Bivort, Benjamin L},
  year={2015},
  volume={112},
  number={21},
  journal={Proc National Acad Sci},
  pmid={25953337},
  issn={0027-8424},
  pmcid={{PMC4450378}},
  pages={6700-6705},
  title={Neuronal control of locomotor handedness in Drosophila},
  doi={10.1073/pnas.1500804112}
}
@article{Haag_Neural_2004,title={Faculty of 1000 evaluation for Neural mechanism underlying complex receptive field properties of motion-sensitive interneurons.}, DOI={10.3410/f.1020791.247808}, journal={F1000 - Post-publication peer review of the biomedical literature}, author={Theunissen, Frederic}, year={2004}}
}
@article{Straw_Multi_2010, title={Multi-camera real-time three-dimensional tracking of multiple flying animals}, volume={8}, DOI={10.1098/rsif.2010.0230}, number={56}, journal={Journal of The Royal Society Interface}, author={Straw, A. D. and Branson, K. and Neumann, T. R. and Dickinson, M. H.}, year={2010}, pages={395–409}}
@article{Churgin_Longitudinal_2017,
  author={Churgin, Matthew A and Jung, {Sang-Kyu} and Yu, {Chih-Chieh} and Chen, Xiangmei and Raizen, David M and {Fang-Yen,} Christopher},
  year={2017},
  volume={6},
  journal={Elife},
  pmid={28537553},
  pages={e26652},
  title={Longitudinal imaging of Caenorhabditis elegans in a microfabricated device reveals variation in behavioral decline during aging},
  doi={10.7554/eLife.26652}
}
@article{Kain_Leg_2013, title={Leg-tracking and automated behavioural classification in Drosophila}, volume={4}, DOI={10.1038/ncomms2908}, number={1}, journal={Nature Communications}, author={Kain, Jamey and Stokes, Chris and Gaudry, Quentin and Song, Xiangzhi and Foley, James and Wilson, Rachel and Bivort, Benjamin De}, year={2013}}
@article{Klapoetke_Independent_2014,
  author={Klapoetke, Nathan C and Murata, Yasunobu and Kim, Sung and Pulver, Stefan R and {Birdsey-Benson,} Amanda and Cho, Yong and Morimoto, Tania K and Chuong, Amy S and Carpenter, Eric J and Tian, Zhijian and Wang, Jun and Xie, Yinlong and Yan, Zhixiang and Zhang, Yong and Chow, Brian Y and Surek, Barbara and Melkonian, Michael and Jayaraman, Vivek and {Constantine-Paton,} Martha and Wong, Gane and Boyden, Edward S},
  year={2014},
  volume={11},
  number={3},
  journal={Nat Methods},
  pmid={24509633},
  abstract={Optogenetic tools enable examination of how specific cell types contribute to brain circuit functions. A long-standing question is whether it is possible to independently activate two distinct neural populations in mammalian brain tissue. Such a capability would enable the study of how different synapses or pathways interact to encode information in the brain. Here we describe two channelrhodopsins, Chronos and Chrimson, discovered through sequencing and physiological characterization of opsins from over 100 species of alga. Chrimson's excitation spectrum is red shifted by 45 nm relative to previous channelrhodopsins and can enable experiments in which red light is preferred. We show minimal visual system–mediated behavioral interference when using the variant {CsChrimson} in neurobehavioral studies in Drosophila melanogaster. Chronos has faster kinetics than previous channelrhodopsins yet is effectively more light sensitive. Together these two reagents enable two-color activation of neural spiking and downstream synaptic transmission in independent neural populations without detectable cross-talk in mouse brain slice.},
  title={Independent optical excitation of distinct neural populations},
  doi={10.1038/nmeth.2836}
}
@article{Prez-Escudero_idTracker_2014,
  author={{P{\'e}rez-Escudero,} Alfonso and {Vicente-Page,} Juli{\'a}n and Hinz, Robert C and Arganda, Sara and de Polavieja, Gonzalo G},
  year={2014},
  volume={11},
  number={7},
  journal={Nat Methods},
  pmid={24880877},
  abstract={Animals in groups touch each other, move in paths that cross, and interact in complex ways. Current video tracking methods sometimes switch identities of unmarked individuals during these interactions. These errors propagate and result in random assignments after a few minutes unless manually corrected. We present {idTracker,} a multitracking algorithm that extracts a characteristic fingerprint from each animal in a video recording of a group. It then uses these fingerprints to identify every individual throughout the video. Tracking by identification prevents propagation of errors, and the correct identities can be maintained indefinitely. {idTracker} distinguishes animals even when humans cannot, such as for size-matched siblings, and reidentifies animals after they temporarily disappear from view or across different videos. It is robust, easy to use and general. We tested it on fish {(Danio} rerio and Oryzias latipes), flies {(Drosophila} melanogaster), ants {(Messor} structor) and mice {(Mus} musculus).},
  issn={1548-7105},
  pages={nmeth.2994},
  title={{idTracker:} tracking individuals in a group by automatic identification of unmarked animals},
  doi={10.1038/nmeth.2994}
}
@article{Branson_High_2009,
  author={Branson, Kristin and Robie, Alice A and Bender, John and Perona, Pietro and Dickinson, Michael H},
  year={2009},
  volume={6},
  number={6},
  journal={Nat Methods},
  pmid={19412169},
  abstract={We present a camera-based method for automatically quantifying the individual and social behaviors of fruit flies, Drosophila melanogaster, interacting in a planar arena. Our system includes machine-vision algorithms that accurately track many individuals without swapping identities and classification algorithms that detect behaviors. The data may be represented as an ethogram that plots the time course of behaviors exhibited by each fly or as a vector that concisely captures the statistical properties of all behaviors displayed in a given period. We found that behavioral differences between individuals were consistent over time and were sufficient to accurately predict gender and genotype. In addition, we found that the relative positions of flies during social interactions vary according to gender, genotype and social environment. We expect that our software, which permits high-throughput screening, will complement existing molecular methods available in Drosophila, facilitating new investigations into the genetic and cellular basis of behavior.},
  issn={1548-7105},
  pmcid={{PMC2734963}},
  pages={nmeth.1328},
  title={High-throughput ethomics in large groups of Drosophila},
  doi={10.1038/nmeth.1328}
}
@article{Swierczek_High_2011,
  author={Swierczek, Nicholas A and Giles, Andrew C and Rankin, Catharine H and Kerr, Rex A},
  year={2011},
  volume={8},
  number={7},
  journal={Nat Methods},
  pmid={21642964},
  file={C:\Users\werkh\OneDrive\Documents\ReadCube Media\Swierczek et al-2011-Nat Methods.pdf},
  abstract={We designed a real-time computer vision system, the {Multi-Worm} Tracker {(MWT),} which can simultaneously quantify the behavior of dozens of Caenorhabditis elegans on a Petri plate at video rates. We examined three traditional behavioral paradigms using this system: spontaneous movement on food, where the behavior changes over tens of minutes; chemotaxis, where turning events must be detected accurately to determine strategy; and habituation of response to tap, where the response is stochastic and changes over time. In each case, manual analysis or automated single-worm tracking would be tedious and time-consuming, but the {MWT} system allowed rapid quantification of behavior with minimal human effort. Thus, this system will enable large-scale forward and reverse genetic screens for complex behaviors.},
  issn={1548-7105},
  pmcid={{PMC3128206}},
  pages={592},
  title={High-throughput behavioral analysis in C. elegans},
  doi={10.1038/nmeth.1625}
}
@article{Donelson_High_2012,title={Correction: High-Resolution Positional Tracking for Long-Term Analysis of Drosophila Sleep and Locomotion Using the “Tracker” Program}, volume={7}, DOI={10.1371/annotation/4c62d454-931e-4c48-841a-a701cb658a1c}, number={8}, journal={PLoS ONE}, author={Donelson, Nathan C. and Kim, Eugene Z. and Slawson, Justin B. and Vecsey, Christopher G. and Huber, Robert and Griffith, Leslie C.}, year={2012}}
@article{Yu_High_2011,
  author={Yu, Xiaoyi and Zhou, Han and Wu, Lingyi and Liu, Qingfeng},
  year={2011},
  journal={2011 Third Chin Conf Intelligent Vis Surveillance},
  abstract={Machine vision systems have been designed for automated monitoring and analysis of social behavior in Drosophila by Herko Dankert. The Ctrax {(The} Caltech Multiple Fly Tracker) is implemented for tracking the Drosophila's movement. But the machine vision method is so sophisticated that it is hard to use by a researcher who is lack of computer technology knowledge. Likewise, most of the machine vision solutions are poor performance for the real time environment. Our work focuses on developing a high-performance application to track moving Drosophila and generate reliable tracks from the video. A light solution to automatically tracking the Drosophila in video is implemented, based on object motion in different parts of the scene. The results of effect tests show that our solution tackles the questions of performance, usability and accuracy in machine vision for bioresearch.},
  pages={69-72},
  title={{High-Performance} Drosophila Movement Tracking},
  doi={10.1109/IVSurv.2011.6157027}
}
@article{Uhlmann_FlyLimbTracker_2017,title={FlyLimbTracker: An active contour based approach for leg segment tracking in unmarked, freely behaving Drosophila}, volume={12}, DOI={10.1371/journal.pone.0173433}, number={4}, journal={Plos One}, author={Uhlmann, Virginie and Ramdya, Pavan and Delgado-Gonzalo, Ricard and Benton, Richard and Unser, Michael}, year={2017}}
@article{Kim_Fly_2016,title={Fly Stampede 2.0: A Next Generation Optomotor Assay for Walking Behavior in Drosophila Melanogaster}, volume={9}, DOI={10.3389/fnmol.2016.00148}, journal={Frontiers in Molecular Neuroscience}, author={Kim, Soomin and Tellez, Kelly and Buchan, Graham and Lebestky, Tim}, year={2016}}
@article{Pereira_Fast_2018,title={Fast animal pose estimation using deep neural networks}, volume={16}, DOI={10.1038/s41592-018-0234-5}, number={1}, journal={Nature Methods}, author={Pereira, Talmo D. and Aldarondo, Diego E. and Willmore, Lindsay and Kislin, Mikhail and Wang, Samuel S.-H. and Murthy, Mala and Shaevitz, Joshua W.}, year={2018}, pages={117–125}}
@article{Noldus_EthoVision_2001,title={EthoVision: A versatile video tracking system for automation of behavioral experiments}, volume={33}, DOI={10.3758/bf03195394}, number={3}, journal={Behavior Research Methods, Instruments, & Computers}, author={Noldus, Lucas P. J. J. and Spink, Andrew J. and Tegelenbosch, Ruud A. J.}, year={2001}, pages={398–414}}
@article{Geissmann_Ethoscopes_2017,
  author={Geissmann, Quentin and Rodriguez, Luis and Beckwith, Esteban J and French, Alice S and Jamasb, Arian R and Gilestro, Giorgio F},
  year={2017},
  volume={15},
  number={10},
  journal={Plos Biol},
  pmid={29049280},
  abstract={Here, we present the use of ethoscopes, which are machines for high-throughput analysis of behavior in Drosophila and other animals. Ethoscopes provide a software and hardware solution that is reproducible and easily scalable. They perform, in real-time, tracking and profiling of behavior by using a supervised machine learning algorithm, are able to deliver behaviorally triggered stimuli to flies in a feedback-loop mode, and are highly customizable and open source. Ethoscopes can be built easily by using {3D} printing technology and rely on Raspberry Pi microcomputers and Arduino boards to provide affordable and flexible hardware. All software and construction specifications are available at http://lab.gilest.ro/ethoscope.},
  issn={1544-9173},
  pages={e2003026},
  title={Ethoscopes: An open platform for high-throughput ethomics},
  doi={10.1371/journal.pbio.2003026}
}
@article{Brown_Ethology_2018,
  author={Brown, Andr{\'e} {EX} and de Bivort, Benjamin},
  year={2018},
  volume={14},
  number={7},
  journal={Nat Phys},
  abstract={The study of animal behaviour, ethology, is becoming more quantitative. New theory is emerging, driven by better imaging and novel representations of animal posture dynamics that span the vast range of relevant behavioural timescales.},
  issn={1745-2473},
  pages={653-657},
  title={Ethology as a physical science},
  doi={10.1038/s41567-018-0093-0}
}
@article{Theobald_Dynamics_2010,
  author={Theobald, Jamie C and Ringach, Dario L and Frye, Mark A},
  year={2010},
  volume={213},
  number={8},
  abstract={For a small flying insect, correcting unplanned course perturbations is essential for navigating through the world. Visual course control relies on estimating optic flow patterns which, in flies, are encoded by interneurons of the third optic ganglion. However, the rules that translate optic flow into flight motor commands remain poorly understood. Here, we measured the temporal dynamics of optomotor responses in tethered flies to optic flow fields about three cardinal axes. For each condition, we used white noise analysis to determine~…},
  pages={1366-1375},
  title={Dynamics of optomotor responses in Drosophila to perturbations in optic flow}
}
@article{in_psychology_Does_2018,AUTHOR={Gorostiza, E. Axel}, TITLE={Does Cognition Have a Role in Plasticity of “Innate Behavior”? A Perspective From Drosophila},JOURNAL={Frontiers in Psychology}, VOLUME={9}, PAGES={1502}, YEAR={2018}, DOI={10.3389/fpsyg.2018.01502}, ISSN={1664-1078}}
@article{Eyjolfsdottir_Detecting_2014,title={Detecting Social Actions of Fruit Flies}, DOI={10.1007/978-3-319-10605-2_50}, journal={Computer Vision – ECCV 2014 Lecture Notes in Computer Science}, author={Eyjolfsdottir, Eyrun and Branson, Steve and Burgos-Artizzu, Xavier P. and Hoopfer, Eric D. and Schor, Jonathan and Anderson, David J. and Perona, Pietro}, year={2014}, pages={772–787}}
@article{Mathis_DeepLabCut_2018,
  author={Mathis, A and Mamidanna, P and Cury, {KM} and Abe, T and Murthy, {VN}},
  year={2018},
  abstract={… However, such systems can be expensive and potentially distracting to animals 13,14 , and~… These
methods can work quite well and are fast, but require sophisticated skeleton models, which~… a,
Training: extract images with distinct postures characteristic of the animal behavior in~… 
},
  title={{DeepLabCut:} markerless pose estimation of user-defined body parts with deep learning}
}
@article{Mnck_BioTracker_2018,
  author={M{\"o}nck, Hauke and J{\"o}rg, Andreas and Falkenhausen, Tobias and Tanke, Julian and Wild, Benjamin and Dormagen, David and Piotrowski, Jonas and Winklmayr, Claudia and Bierbach, David and Landgraf, Tim},
  year={2018},
  file={C:\Users\werkh\OneDrive\Documents\ReadCube Media\Mnck et al-2018-arXiv preprint arXiv180307985.pdf},
  abstract={The study of animal behavior increasingly relies on (semi-) automatic methods for the extraction of relevant behavioral features from video or picture data. To date, several specialized software products exist to detect and track animals' positions in simple (laboratory) environments. Tracking animals in their natural environments, however, often requires substantial customization of the image processing algorithms to the problem-specific image characteristics. Here we introduce {BioTracker,} an open-source computer~…},
  title={{BioTracker:} An {Open-Source} Computer Vision Framework for Visual Animal Tracking}
}
@article{Rosner_Behavioural_2009,
  author={Rosner, R and Egelhaaf, M and Warzecha, {A.-K.}},
  year={2009},
  volume={213},
  number={2},
  issn={0022-0949},
  pages={331-338},
  title={Behavioural state affects motion-sensitive neurones in the fly visual system},
  doi={10.1242/jeb.035386}
}
@article{Ayroles_Behavioral_2015,
  author={Ayroles, Julien F and Buchanan, Sean M and {O’Leary,} Chelsea and {Skutt-Kakaria,} Kyobi and Grenier, Jennifer K and Clark, Andrew G and Hartl, Daniel L and de Bivort, Benjamin L},
  year={2015},
  volume={112},
  number={21},
  journal={Proc National Acad Sci},
  pmid={25953335},
  abstract={Quantitative genetics has primarily focused on describing genetic effects on trait means and largely ignored the effect of alternative alleles on trait variability, potentially missing an important axis of genetic variation contributing to phenotypic differences among individuals. To study the genetic effects on individual-to-individual phenotypic variability (or intragenotypic variability), we used Drosophila inbred lines and measured the spontaneous locomotor behavior of flies walking individually in Y-shaped mazes, focusing on variability in locomotor handedness, an assay optimized to measure variability. We discovered that some lines had consistently high levels of intragenotypic variability among individuals, whereas lines with low variability behaved as although they tossed a coin at each left/right turn decision. We demonstrate that the degree of variability is itself heritable. Using a genome-wide association study {(GWAS)} for the degree of intragenotypic variability as the phenotype across lines, we identified several genes expressed in the brain that affect variability in handedness without affecting the mean. One of these genes, Ten-a, implicates a neuropil in the central complex of the fly brain as influencing the magnitude of behavioral variability, a brain region involved in sensory integration and locomotor coordination. We validated these results using genetic deficiencies, null alleles, and inducible {RNAi} transgenes. Our study reveals the constellation of phenotypes that can arise from a single genotype and shows that different genetic backgrounds differ dramatically in their propensity for phenotypic variabililty. Because traditional mean-focused {GWASs} ignore the contribution of variability to overall phenotypic variation, current methods may miss important links between genotype and phenotype.},
  issn={0027-8424},
  pmcid={{PMC4450409}},
  pages={6706-6711},
  title={Behavioral idiosyncrasy reveals genetic control of phenotypic variability},
  doi={10.1073/pnas.1503830112}
}
@article{Dankert_Automated_2009, title={Automated monitoring and analysis of social behavior in Drosophila}, volume={6}, DOI={10.1038/nmeth.1310}, number={4}, journal={Nature Methods}, author={Dankert, Heiko and Wang, Liming and Hoopfer, Eric D and Anderson, David J and Perona, Pietro}, year={2009}, pages={297–303}}
@article{Evans_An_2011,
  author={Evans, O and Paulk, {AC} and van one, Swinderen~- B},
  year={2011},
  journal={{PloS} one},
  abstract={Background Mutations that cause learning and memory defects in Drosophila melanogaster have been found to also compromise visual responsiveness and attention. A better understanding of attention-like defects in such Drosophila mutants therefore requires a more detailed characterization of visual responsiveness across a range of visual parameters. {Methodology/Principal} Findings We designed an automated behavioral paradigm for efficiently dissecting visual responsiveness in Drosophila. Populations of flies walk through~…},
  title={An automated paradigm for Drosophila visual psychophysics}
}
@article{Maimon_Active_2010,
  author={Maimon, Gaby and Straw, Andrew D and Dickinson, Michael H},
  year={2010},
  volume={13},
  number={3},
  issn={1097-6256},
  pages={393-399},
  title={Active flight increases the gain of visual motion processing in Drosophila},
  doi={10.1038/nn.2492}
}
@article{Liu_A_2018,
  author={Liu, Guangda and Nath, Tanmay and Linneweber, Gerit A and Claeys, Annelies and Guo, Zhengyu and Li, Jin and Bengochea, Mercedes and Backer, Steve and Weyn, Barbara and Sneyders, Manu and Nicasy, Hans and Yu, Peng and Scheunders, Paul and Hassan, Bassem A},
  year={2018},
  volume={14},
  number={8},
  journal={Plos Comput Biol},
  pmid={30161262},
  issn={{1553-734X}},
  pages={e1006410},
  title={A simple computer vision pipeline reveals the effects of isolation on social interaction dynamics in Drosophila},
  doi={10.1371/journal.pcbi.1006410}
}
@article{Itskovits_A_2017,title={A multi-animal tracker for studying complex behaviors}, volume={15}, DOI={10.1186/s12915-017-0363-9}, number={1}, journal={BMC Biology}, author={Itskovits, Eyal and Levine, Amir and Cohen, Ehud and Zaslaver, Alon}, year={2017}}
@article{diegelmann_2006, title={Genetic dissociation of acquisition and memory strength in the heat-box spatial learning paradigm in Drosophila}, volume={13}, DOI={10.1101/lm.45506}, number={1}, journal={Learning & Memory}, author={Diegelmann, S.}, year={2006}, pages={72–83}} 
@article{haag_arenz_serbe_gabbiani_borst_2016, title={Complementary mechanisms create direction selectivity in the fly}, volume={5}, DOI={10.7554/elife.17421}, journal={eLife}, author={Haag, Juergen and Arenz, Alexander and Serbe, Etienne and Gabbiani, Fabrizio and Borst, Alexander}, year={2016}} 
@article{heisenberg_wolf_1984, title={Vision in Drosophila}, DOI={10.1007/978-3-642-69936-8}, journal={Studies of Brain Function}, author={Heisenberg, Martin and Wolf, Reinhard}, year={1984}} 
@article{ostrowski_kahsai_kramer_knutson_zars_2015, title={Place memory retention in Drosophila}, volume={123}, DOI={10.1016/j.nlm.2015.06.015}, journal={Neurobiology of Learning and Memory}, author={Ostrowski, Daniela and Kahsai, Lily and Kramer, Elizabeth F. and Knutson, Patrick and Zars, Troy}, year={2015}, pages={217–224}} 
@article{putz_2002, title={Memories in Drosophila Heat-box Learning}, volume={9}, DOI={10.1101/lm.50402}, number={5}, journal={Learning & Memory}, author={Putz, G.}, year={2002}, pages={349–359}} 
@article{sitaraman_zars_zars_2007, title={Reinforcement pre-exposure enhances spatial memory formation in Drosophila}, volume={193}, DOI={10.1007/s00359-007-0243-9}, number={8}, journal={Journal of Comparative Physiology A}, author={Sitaraman, Divya and Zars, Melissa and Zars, Troy}, year={2007}, pages={903–908}} @article{sitaraman_zars_zars_2010, title={Place memory formation in Drosophila is independent of proper octopamine signaling}, volume={196}, DOI={10.1007/s00359-010-0517-5}, number={4}, journal={Journal of Comparative Physiology A}, author={Sitaraman, Divya and Zars, Melissa and Zars, Troy}, year={2010}, pages={299–305}} @article{wustmann_heisenberg_1997, title={Behavioral manipulation of retrieval in a spatial memory task for Drosophila melanogaster.}, volume={4}, DOI={10.1101/lm.4.4.328}, number={4}, journal={Learning & Memory}, author={Wustmann, G and Heisenberg, M}, year={1997}, pages={328–336}} @article{wustmann_rein_wolf_heisenberg_1996, title={A new paradigm for operant conditioning of Drosophila melanogaster}, volume={179}, DOI={10.1007/bf00194996}, number={3}, journal={Journal of Comparative Physiology A}, author={Wustmann, G. and Rein, K. and Wolf, R. and Heisenberg, M.}, year={1996}} 
@article{zars_zars_2006, title={High and low temperatures have unequal reinforcing properties in Drosophila spatial learning}, volume={192}, DOI={10.1007/s00359-006-0109-6}, number={7}, journal={Journal of Comparative Physiology A}, author={Zars, Melissa and Zars, Troy}, year={2006}, pages={727–735}}

@article{gorostiza_2018, author={Gorostiza, E. Axel}, title={Does Cognition Have a Role in Plasticity of “Innate Behavior”? A Perspective From Drosophila}, journal={Frontiers in Psychology}, volume={9}, pages={1502}, year={2018}, doi{10.3389/fpsyg.2018.01502}, issn={1664-1078}
}
@article {Cruz572792,
	author = {Cruz, Tomas Lopes and Fujiwara, Terufumi E and Varela, Nelia and Mohammad, Farhan and Claridge-Chang, Adam and Chiappe, M Eugenia},
	title = {Motor context coordinates visually guided walking in Drosophila},
	elocation-id = {572792},
	year = {2019},
	doi = {10.1101/572792},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Course control is critical for the acquisition of spatial information during exploration and navigation, and it is thought to rely on neural circuits that process locomotive-related multimodal signals. However, which circuits underlie this control, and how multimodal information contributes to the control system are questions poorly understood. We used Virtual Reality to examine the role of self-generated visual signals (visual feedback) on the control of exploratory walking in flies. Exploratory flies display two distinct motor contexts, characterized by low speed and fast rotations, or by high speed and slow rotations, respectively. Flies use visual feedback to control body rotations, but in a motor-context specific manner, primarily when walking at high speed. Different populations of visual motion-sensitive cells estimate body rotations via congruent, multimodal inputs, and drive compensatory rotations. However, their effective contribution to course control is dynamically tuned by a speed-related signal. Our data identifies visual networks with a multimodal circuit mechanism for adaptive course control and suggests models for how visual feedback is combined with internal signals to guide exploratory course control.},	eprint = {https://www.biorxiv.org/content/early/2019/03/11/572792.full.pdf},
	journal = {bioRxiv}
}
@article{griebel_2014, title={Faculty of 1000 evaluation for Noninvasive optical inhibition with a red-shifted microbial rhodopsin.}, DOI={10.3410/f.718482076.793498459}, journal={F1000 - Post-publication peer review of the biomedical literature}, author={Griebel, Guy}, year={2014}} @article{klapoetke_murata_kim_pulver_birdsey-benson_cho_morimoto_chuong_carpenter_tian_et al._2014, title={Independent optical excitation of distinct neural populations}, volume={11}, DOI={10.1038/nmeth.2836}, number={3}, journal={Nature Methods}, author={Klapoetke, Nathan C and Murata, Yasunobu and Kim, Sung Soo and Pulver, Stefan R and Birdsey-Benson, Amanda and Cho, Yong Ku and Morimoto, Tania K and Chuong, Amy S and Carpenter, Eric J and Tian, Zhijian and et al.}, year={2014}, pages={338–346}}

@article{YANG2013799,
title = "Flies Cope with Uncontrollable Stress by Learned Helplessness",
journal = "Current Biology",
volume = "23",
number = "9",
pages = "799 - 803",
year = "2013",
issn = "0960-9822",
doi = "https://doi.org/10.1016/j.cub.2013.03.054",
author = "Zhenghong Yang and Franco Bertolucci and Reinhard Wolf and Martin Heisenberg"
}
@article{romero-ferrero_2019, title={idtracker.ai: tracking all individuals in small or large collectives of unmarked animals}, volume={16}, DOI={10.1038/s41592-018-0295-5}, number={2}, journal={Nature Methods}, author={Romero-Ferrero, Francisco and Bergomi, Mattia G. and Hinz, Robert C. and Heras, Francisco J. H. and Polavieja, Gonzalo G. De}, year={2019}, pages={179–182}}

@article{schneider_2018, title={Can Drosophila melanogaster tell who’s who?}, volume={13}, DOI={10.1371/journal.pone.0205043}, number={10}, journal={Plos One}, author={Schneider, Jonathan and Murali, Nihal and Taylor, Graham W. and Levine, Joel D.}, year={2018}}

@article{Scaplen_Automated_2019,
  number={1},
  doi={10.1038/s41598-019-40952-5},
  journal={Sci Rep},
  pmid={30872709},
  volume={9},
  issn={2045-2322},
  author={Scaplen, Kristin M and Mei, Nicholas J and Bounds, Hayley A and Song, Sophia L and Azanchi, Reza and Kaun, Karla R},
  year={2019},
  title={Automated real-time quantification of group locomotor activity in Drosophila melanogaster.},
  pages={4427}
}

@article{berman_choi_bialek_shaevitz_2014, title={Mapping the stereotyped behaviour of freely moving fruit flies}, volume={11}, DOI={10.1098/rsif.2014.0672}, number={99}, journal={Journal of The Royal Society Interface}, author={Berman, G. J. and Choi, D. M. and Bialek, W. and Shaevitz, J. W.}, year={2014}, pages={20140672–20140672}}

@article{Crall_2016_cockroach,
title = "Social context modulates idiosyncrasy of behaviour in the gregarious cockroach Blaberus discoidalis",
journal = "Animal Behaviour",
volume = "111",
pages = "297 - 305",
year = "2016",
issn = "0003-3472",
doi = "https://doi.org/10.1016/j.anbehav.2015.10.032",
author = "James D. Crall and AndrÃ© D. Souffrant and Dominic Akandwanaho and Sawyer D. Hescock and Sarah E. Callan and W. Melissa Coronado and Maude W. Baldwin and Benjamin L. de Bivort",
keywords = "animal personality, behaviour, cockroach, collective behaviour, group composition, individuality, phototaxis, sociality"
}